# üïµÔ∏è‚Äç‚ôÇÔ∏è Proposta: Motor de Ingest√£o Universal (Seth VII)

Esta an√°lise avalia a viabilidade do plano proposto pelo DeepSeek e prop√µe uma arquitetura otimizada para o **Seth VII**, focando em superar a limita√ß√£o das APIs governamentais atrav√©s da extra√ß√£o de dados n√£o estruturados (Web, PDF, MD, etc.).

---

## ‚öñÔ∏è An√°lise de Viabilidade (Plano DeepSeek)

O plano do DeepSeek √© **altamente vi√°vel** e ataca o problema correto: a "cegueira" de dados causada por APIs limitadas. No entanto, para o contexto do Seth VII, proponho as seguintes melhorias:

### Pontos Fortes do Plano DeepSeek:
- **Foco em Formatos:** A detec√ß√£o autom√°tica de PDF/HTML √© essencial.
- **Arquitetura Modular:** Separar `crawlers` de `parsers` facilita a manuten√ß√£o.
- **Custo Zero:** Uso de bibliotecas open-source (Playwright, Tesseract.js).

### Melhorias Propostas para o Seth VII:
1. **Intelig√™ncia de Extra√ß√£o (LLM-First):** Em vez de `parsers` r√≠gidos para cada site, usar o **Brain Agent** para extrair dados estruturados de textos brutos extra√≠dos de PDFs e HTMLs. Isso reduz o c√≥digo de manuten√ß√£o.
2. **Sistema de "Deep Scout":** Integrar o Agente de Aus√™ncia diretamente no pipeline de ingest√£o para buscar especificamente por editais e licita√ß√µes quando uma promessa de obra √© detectada.
3. **Cache de Snapshots:** Como j√° implementamos o `SnapshotService`, ele deve ser a base para armazenar os arquivos brutos (PDFs/HTMLs) antes do processamento.

---

## üèóÔ∏è Arquitetura Sugerida: "Seth Ingestion Engine"

Proponho a cria√ß√£o de um novo diret√≥rio `server/ingestion/` com a seguinte l√≥gica:

### 1. Router de Formato (Universal Router)
O `BrowserScraper` atual ser√° expandido para detectar o `Content-Type` antes de processar.
- **HTML:** Segue o fluxo atual de limpeza.
- **PDF:** Encaminha para o `PDFParser` (usando `pdf-parse`).
- **CSV/XLSX:** Encaminha para o `TableParser`.

### 2. Pipeline de Processamento
```mermaid
graph TD
    A[Scout Agent] -->|URL| B[Universal Router]
    B -->|HTML| C[BrowserScraper]
    B -->|PDF| D[PDF Service]
    B -->|CSV/XLSX| E[Table Service]
    C & D & E --> F[Raw Content]
    F --> G[Brain Agent / LLM]
    G -->|Dados Estruturados| H[Supabase]
```

---

## üõ†Ô∏è Plano de Implementa√ß√£o (Checkpoints)

### Checkpoint 10: Base de Ingest√£o Multi-Formato
- Instalar depend√™ncias: `pdf-parse`, `mammoth`, `xlsx`.
- Criar `server/services/ingestion.service.ts` para gerenciar o roteamento.
- Atualizar `BrowserScraper` para lidar com downloads de arquivos.

### Checkpoint 11: Integra√ß√£o com Di√°rios Oficiais (DOU)
- Criar crawler espec√≠fico para o IN.gov.br (DOU).
- Implementar parser de PDF para extrair atos de nomea√ß√£o e editais.

### Checkpoint 12: Extra√ß√£o Sem√¢ntica via IA
- Ajustar o `BrainAgent` para receber conte√∫dos brutos de documentos longos (PDFs) e realizar "chunking" (divis√£o em partes) para an√°lise.

---

## üí∞ An√°lise de Custos e Limites

| Recurso | Solu√ß√£o | Custo | Limite |
| :--- | :--- | :--- | :--- |
| **Processamento** | Railway / Sandbox | $0 | CPU/RAM do plano free |
| **Armazenamento** | Supabase Storage | $0 | 1GB (Suficiente para ~10k PDFs) |
| **OCR** | Tesseract.js | $0 | Execu√ß√£o local (CPU intensive) |
| **IA (An√°lise)** | Pollinations / OpenRouter | $0 | Rate limits das APIs |

---

## üèÅ Conclus√£o e Recomenda√ß√£o

A expans√£o para fontes n√£o estruturadas √© o **pr√≥ximo salto evolutivo** do Seth VII. Ela permitir√° que o sistema audite n√£o apenas o que o governo "quer mostrar" via API, mas o que ele "publica por obriga√ß√£o" em Di√°rios Oficiais e editais.

**Recomenda√ß√£o Imediata:**
1. Come√ßar pela implementa√ß√£o do **Parser de PDF** (DOU e Editais).
2. Integrar o **Scout** para buscar em portais de transpar√™ncia estaduais que n√£o possuem API.

Deseja que eu comece a implementa√ß√£o do **Checkpoint 10 (Base de Ingest√£o Multi-Formato)** agora?
